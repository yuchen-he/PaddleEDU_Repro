{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0582729d",
   "metadata": {},
   "source": [
    "### 定义torch的FlatFolderDataset\n",
    "\n",
    "注意将随机的部分固定住，这里随机的部分为RandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796898f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class FlatFolderDataset(Dataset):\n",
    "    def __init__(self, content_root, style_root):\n",
    "        super(FlatFolderDataset, self).__init__()\n",
    "        self.content_root = content_root\n",
    "        self.paths = os.listdir(self.content_root)\n",
    "        self.style_root = style_root\n",
    "        self.transform = self.data_transform(128)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        content_img = Image.open(os.path.join(self.content_root, \n",
    "                                               path)).convert('RGB')\n",
    "        content_img = content_img.resize((128, 128), Image.BILINEAR)\n",
    "        content_img = self.transform(content_img)\n",
    "        style_img = Image.open(self.style_root).convert('RGB')\n",
    "        style_img = style_img.resize((128, 128), Image.BILINEAR)\n",
    "        style_img = self.transform(style_img)[:3, :, :]\n",
    "        return content_img, style_img\n",
    "    \n",
    "    def data_transform(self, crop_size=128):\n",
    "        transform_list = [\n",
    "            transforms.RandomCrop(crop_size),\n",
    "            transforms.ToTensor()\n",
    "            ]\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def name(self):\n",
    "        return 'FlatFolderDataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd9fef",
   "metadata": {},
   "source": [
    "### torch读入一张图片\n",
    "这里'/workspace/visCVPR2021/ZBK/data/test1/'中只有一张图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1c81a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_image_t: [0.45882353 0.45490196 0.4509804  0.45490196 0.47058824 0.48235294]\n",
      "style_image_t: [0.1254902  0.10196079 0.16078432 0.2901961  0.20784314 0.26666668]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "dataset = FlatFolderDataset('/workspace/visCVPR2021/ZBK/data/coco/test1/', '/workspace/visCVPR2021/ZBK/data/starrynew.png')\n",
    "data_iter = DataLoader(dataset, batch_size=1, num_workers=0)\n",
    "for i, item in enumerate(data_iter):\n",
    "    if i>0:\n",
    "        break\n",
    "    content_image_t = np.array(item[0].data.cpu().numpy())\n",
    "    print('content_image_t:', content_image_t[0,0,0,:6])\n",
    "    style_image_t = np.array(item[1].data.cpu().numpy())\n",
    "    print('style_image_t:', style_image_t[0,0,0,:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cd4654",
   "metadata": {},
   "source": [
    "### 定义paddle的LapStyleDataset\n",
    "\n",
    "注意将随机的部分固定住，这里随机的部分为RandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b062b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision import transforms\n",
    "from paddle.io import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class LapStyleDataset(Dataset):\n",
    "    def __init__(self, content_root, style_root):\n",
    "        super(LapStyleDataset, self).__init__()\n",
    "        self.content_root = content_root\n",
    "        self.paths = os.listdir(self.content_root)\n",
    "        self.style_root = style_root\n",
    "        self.transform = self.data_transform(128)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        content_img = Image.open(os.path.join(self.content_root,\n",
    "                                               path)).convert('RGB')\n",
    "        content_img = content_img.resize((128, 128), Image.BILINEAR)\n",
    "        content_img = self.transform(content_img)\n",
    "        style_img = Image.open(self.style_root).convert('RGB')\n",
    "        style_img = style_img.resize((128, 128), Image.BILINEAR)\n",
    "        style_img = self.transform(style_img)[:3, :, :]\n",
    "        return content_img, style_img\n",
    "\n",
    "    def data_transform(self, crop_size=136):\n",
    "        transform_list = [\n",
    "            transforms.RandomCrop(crop_size), \n",
    "            transforms.ToTensor()\n",
    "            ] \n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def name(self):\n",
    "        return 'LapStyleDataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088b816",
   "metadata": {},
   "source": [
    "### paddle读入一张图片\n",
    "这里'/workspace/visCVPR2021/ZBK/data/test1/'中只有一张图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bed559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_image_p: [0.45882356 0.454902   0.45098042 0.454902   0.47058827 0.48235297]\n",
      "style_image_p: [0.1254902  0.10196079 0.16078432 0.2901961  0.20784315 0.26666668]\n"
     ]
    }
   ],
   "source": [
    "from paddle.io import DataLoader\n",
    "dataset = LapStyleDataset('/workspace/visCVPR2021/ZBK/data/coco/test1/', '/workspace/visCVPR2021/ZBK/data/starrynew.png')\n",
    "data_iter = DataLoader(dataset, batch_size=1, num_workers=0)\n",
    "for i, item in enumerate(data_iter):\n",
    "    if i>0:\n",
    "        break\n",
    "    content_image_p = np.array(item[0].numpy())\n",
    "    print('content_image_p:', content_image_p[0,0,0,:6])\n",
    "    style_image_p = np.array(item[1].numpy())\n",
    "    print('style_image_p:', style_image_p[0,0,0,:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbc77c",
   "metadata": {},
   "source": [
    "### 比较paddle和torch的输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753150b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_image_t is equal to content_image_p\n",
      "style_image_t is equal to style_image_p\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.testing.assert_allclose(content_image_t, content_image_p)\n",
    "print('content_image_t is equal to content_image_p')\n",
    "np.testing.assert_allclose(style_image_t, style_image_p)\n",
    "print('style_image_t is equal to style_image_p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba0dc9",
   "metadata": {},
   "source": [
    "### 比较输出\n",
    "若paddle和torch的输出数据差异很小（万分之一误差内），则视为数据处理正确，继续下一步；\n",
    "\n",
    "若差异较大，需要打印中间数据，输出并对比差异，定位差异点，并分析问题所在。\n",
    "\n",
    "### 注意：\n",
    "1. 在对齐数据处理时，要将随机的部分固定住，如随机剪裁等。\n",
    "2. 确保torch与paddle读入的是同一张图像（可以建立一个只有一张图像的文件夹）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c113c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
